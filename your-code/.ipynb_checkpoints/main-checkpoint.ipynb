{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources (README.md file)\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Exploring the Data\n",
    "\n",
    "In this challenge, we will examine all salaries of employees of the City of Chicago. We will start by loading the dataset and examining its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "salaries = pd.read_csv('../Current_Employee_Names__Salaries__and_Position_Titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the `salaries` dataset using the `head` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Department</th>\n",
       "      <th>Full or Part-Time</th>\n",
       "      <th>Salary or Hourly</th>\n",
       "      <th>Typical Hours</th>\n",
       "      <th>Annual Salary</th>\n",
       "      <th>Hourly Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARON,  JEFFERY M</td>\n",
       "      <td>SERGEANT</td>\n",
       "      <td>POLICE</td>\n",
       "      <td>F</td>\n",
       "      <td>Salary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101442.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARON,  KARINA</td>\n",
       "      <td>POLICE OFFICER (ASSIGNED AS DETECTIVE)</td>\n",
       "      <td>POLICE</td>\n",
       "      <td>F</td>\n",
       "      <td>Salary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94122.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AARON,  KIMBERLEI R</td>\n",
       "      <td>CHIEF CONTRACT EXPEDITER</td>\n",
       "      <td>GENERAL SERVICES</td>\n",
       "      <td>F</td>\n",
       "      <td>Salary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101592.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABAD JR,  VICENTE M</td>\n",
       "      <td>CIVIL ENGINEER IV</td>\n",
       "      <td>WATER MGMNT</td>\n",
       "      <td>F</td>\n",
       "      <td>Salary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110064.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABASCAL,  REECE E</td>\n",
       "      <td>TRAFFIC CONTROL AIDE-HOURLY</td>\n",
       "      <td>OEMC</td>\n",
       "      <td>P</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                              Job Titles  \\\n",
       "0    AARON,  JEFFERY M                                SERGEANT   \n",
       "1      AARON,  KARINA   POLICE OFFICER (ASSIGNED AS DETECTIVE)   \n",
       "2  AARON,  KIMBERLEI R                CHIEF CONTRACT EXPEDITER   \n",
       "3  ABAD JR,  VICENTE M                       CIVIL ENGINEER IV   \n",
       "4    ABASCAL,  REECE E             TRAFFIC CONTROL AIDE-HOURLY   \n",
       "\n",
       "         Department Full or Part-Time Salary or Hourly  Typical Hours  \\\n",
       "0            POLICE                 F           Salary            NaN   \n",
       "1            POLICE                 F           Salary            NaN   \n",
       "2  GENERAL SERVICES                 F           Salary            NaN   \n",
       "3       WATER MGMNT                 F           Salary            NaN   \n",
       "4              OEMC                 P           Hourly           20.0   \n",
       "\n",
       "   Annual Salary  Hourly Rate  \n",
       "0       101442.0          NaN  \n",
       "1        94122.0          NaN  \n",
       "2       101592.0          NaN  \n",
       "3       110064.0          NaN  \n",
       "4            NaN        19.86  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from looking at the `head` function that there is quite a bit of missing data. Let's examine how much missing data is in each column. Produce this output in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33183 entries, 0 to 33182\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Name               33183 non-null  object \n",
      " 1   Job Titles         33183 non-null  object \n",
      " 2   Department         33183 non-null  object \n",
      " 3   Full or Part-Time  33183 non-null  object \n",
      " 4   Salary or Hourly   33183 non-null  object \n",
      " 5   Typical Hours      8022 non-null   float64\n",
      " 6   Annual Salary      25161 non-null  float64\n",
      " 7   Hourly Rate        8022 non-null   float64\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 11.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "salaries.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the count of hourly vs. salaried employees. Write the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary or Hourly\n",
      "Salary    25161\n",
      "Hourly     8022\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "# Salary or Hourly\n",
    "unique_values = salaries['Salary or Hourly'].value_counts()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this information indicates is that the table contains information about two types of employees - salaried and hourly. Some columns apply only to one type of employee while other columns only apply to another kind. This is why there are so many missing values. Therefore, we will not do anything to handle the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different departments in the city. List all departments and the count of employees in each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLICE' 'GENERAL SERVICES' 'WATER MGMNT' 'OEMC' 'CITY COUNCIL'\n",
      " 'AVIATION' 'STREETS & SAN' 'FIRE' 'FAMILY & SUPPORT' 'PUBLIC LIBRARY'\n",
      " 'TRANSPORTN' \"MAYOR'S OFFICE\" 'HEALTH' 'BUSINESS AFFAIRS' 'LAW' 'FINANCE'\n",
      " 'CULTURAL AFFAIRS' 'COMMUNITY DEVELOPMENT' 'PROCUREMENT' 'BUILDINGS'\n",
      " 'ANIMAL CONTRL' 'CITY CLERK' 'BOARD OF ELECTION' 'DISABILITIES'\n",
      " 'HUMAN RESOURCES' 'DoIT' 'BUDGET & MGMT' 'TREASURER' 'INSPECTOR GEN'\n",
      " 'HUMAN RELATIONS' 'COPA' 'BOARD OF ETHICS' 'POLICE BOARD' 'ADMIN HEARNG'\n",
      " 'LICENSE APPL COMM']\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "unique_values = salaries['Department'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "POLICE                   13414\n",
      "FIRE                      4641\n",
      "STREETS & SAN             2198\n",
      "OEMC                      2102\n",
      "WATER MGMNT               1879\n",
      "AVIATION                  1629\n",
      "TRANSPORTN                1140\n",
      "PUBLIC LIBRARY            1015\n",
      "GENERAL SERVICES           980\n",
      "FAMILY & SUPPORT           615\n",
      "FINANCE                    560\n",
      "HEALTH                     488\n",
      "CITY COUNCIL               411\n",
      "LAW                        407\n",
      "BUILDINGS                  269\n",
      "COMMUNITY DEVELOPMENT      207\n",
      "BUSINESS AFFAIRS           171\n",
      "COPA                       116\n",
      "BOARD OF ELECTION          107\n",
      "DoIT                        99\n",
      "PROCUREMENT                 92\n",
      "INSPECTOR GEN               87\n",
      "MAYOR'S OFFICE              85\n",
      "CITY CLERK                  84\n",
      "ANIMAL CONTRL               81\n",
      "HUMAN RESOURCES             79\n",
      "CULTURAL AFFAIRS            65\n",
      "BUDGET & MGMT               46\n",
      "ADMIN HEARNG                39\n",
      "DISABILITIES                28\n",
      "TREASURER                   22\n",
      "HUMAN RELATIONS             16\n",
      "BOARD OF ETHICS              8\n",
      "POLICE BOARD                 2\n",
      "LICENSE APPL COMM            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values = salaries['Department'].value_counts()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Hypothesis Tests\n",
    "\n",
    "In this section of the lab, we will test whether the hourly wage of all hourly workers is significantly different from $30/hr. Import the correct one sample test function from scipy and perform the hypothesis test for a 95% two sided confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from scipy.stats import ttest_1samp\n",
    "# Hourly Rate\n",
    "# Hourly     8022\n",
    "\n",
    "'''\n",
    "mu = 30        # media poblacional\n",
    "\n",
    "mu_hat = 32.78855771628024    # media muestral, media del experimento\n",
    "\n",
    "std_hat = 12.111817701093825    # std muestral, std del experimento\n",
    "\n",
    "n = 8022         # tamaño de la muestra\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.86, 46.1 , 35.6 ,  2.65, 17.68, 46.1 , 21.43, 35.6 , 25.1 ,\n",
       "       20.  , 36.21, 35.6 , 45.07, 44.88, 46.1 , 48.25, 36.22, 40.2 ,\n",
       "       36.13, 40.2 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_hourly = np.array(salaries['Hourly Rate'].dropna())\n",
    "\n",
    "array_hourly[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8022"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 32.78855771628024\n",
      "std 12.111817701093825\n"
     ]
    }
   ],
   "source": [
    "mean_hourly = array_hourly.mean()\n",
    "std_hourly = array_hourly.std()\n",
    "print('mean', mean_hourly)\n",
    "print('std', std_hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=20.6198057854942, pvalue=4.3230240486229894e-92, df=8021)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test = ttest_1samp(array_hourly, 30, alternative='two-sided')\n",
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.046248541993936, 56.53086689056654)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence_interval = stats.t.interval(0.95, len(array_hourly)-1, loc=mean_hourly, scale=std_hourly)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\demia\\anaconda3\\lib\\site-packages\\scipy\\stats\\_morestats.py:1816: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.930728554725647, pvalue=0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "shapiro(array_hourly)  # es normal, NO puedo rechazar H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.06743331,  1.09904579,  0.23212389, -2.48835959, -1.24742281,\n",
       "        1.09904579, -0.93780785,  0.23212389, -0.63479801, -1.05587436,\n",
       "        0.28248793,  0.23212389,  1.01400488,  0.99831772,  1.09904579,\n",
       "        1.27655837,  0.28331357,  0.61191825,  0.27588281,  0.61191825])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_array = (array_hourly - mean_hourly) / std_hourly\n",
    "normalized_array[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_1samp in module scipy.stats._stats_py:\n",
      "\n",
      "ttest_1samp(a, popmean, axis=0, nan_policy='propagate', alternative='two-sided', *, keepdims=False)\n",
      "    Calculate the T-test for the mean of ONE group of scores.\n",
      "    \n",
      "    This is a test for the null hypothesis that the expected value\n",
      "    (mean) of a sample of independent observations `a` is equal to the given\n",
      "    population mean, `popmean`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Sample observation.\n",
      "    popmean : float or array_like\n",
      "        Expected value in null hypothesis. If array_like, then its length along\n",
      "        `axis` must equal 1, and it must otherwise be broadcastable with `a`.\n",
      "    axis : int or None, default: 0\n",
      "        If an int, the axis of the input along which to compute the statistic.\n",
      "        The statistic of each axis-slice (e.g. row) of the input will appear in a\n",
      "        corresponding element of the output.\n",
      "        If ``None``, the input will be raveled before computing the statistic.\n",
      "    nan_policy : {'propagate', 'omit', 'raise'}\n",
      "        Defines how to handle input NaNs.\n",
      "        \n",
      "        - ``propagate``: if a NaN is present in the axis slice (e.g. row) along\n",
      "          which the  statistic is computed, the corresponding entry of the output\n",
      "          will be NaN.\n",
      "        - ``omit``: NaNs will be omitted when performing the calculation.\n",
      "          If insufficient data remains in the axis slice along which the\n",
      "          statistic is computed, the corresponding entry of the output will be\n",
      "          NaN.\n",
      "        - ``raise``: if a NaN is present, a ``ValueError`` will be raised.\n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "        \n",
      "        * 'two-sided': the mean of the underlying distribution of the sample\n",
      "          is different than the given population mean (`popmean`)\n",
      "        * 'less': the mean of the underlying distribution of the sample is\n",
      "          less than the given population mean (`popmean`)\n",
      "        * 'greater': the mean of the underlying distribution of the sample is\n",
      "          greater than the given population mean (`popmean`)\n",
      "    keepdims : bool, default: False\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : `~scipy.stats._result_classes.TtestResult`\n",
      "        An object with the following attributes:\n",
      "        \n",
      "        statistic : float or array\n",
      "            The t-statistic.\n",
      "        pvalue : float or array\n",
      "            The p-value associated with the given alternative.\n",
      "        df : float or array\n",
      "            The number of degrees of freedom used in calculation of the\n",
      "            t-statistic; this is one less than the size of the sample\n",
      "            (``a.shape[axis]``).\n",
      "        \n",
      "            .. versionadded:: 1.10.0\n",
      "        \n",
      "        The object also has the following method:\n",
      "        \n",
      "        confidence_interval(confidence_level=0.95)\n",
      "            Computes a confidence interval around the population\n",
      "            mean for the given confidence level.\n",
      "            The confidence interval is returned in a ``namedtuple`` with\n",
      "            fields `low` and `high`.\n",
      "        \n",
      "            .. versionadded:: 1.10.0\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The statistic is calculated as ``(np.mean(a) - popmean)/se``, where\n",
      "    ``se`` is the standard error. Therefore, the statistic will be positive\n",
      "    when the sample mean is greater than the population mean and negative when\n",
      "    the sample mean is less than the population mean.\n",
      "    \n",
      "    Beginning in SciPy 1.9, ``np.matrix`` inputs (not recommended for new\n",
      "    code) are converted to ``np.ndarray`` before the calculation is performed. In\n",
      "    this case, the output will be a scalar or ``np.ndarray`` of appropriate shape\n",
      "    rather than a 2D ``np.matrix``. Similarly, while masked elements of masked\n",
      "    arrays are ignored, the output will be a scalar or ``np.ndarray`` rather than a\n",
      "    masked array with ``mask=False``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Suppose we wish to test the null hypothesis that the mean of a population\n",
      "    is equal to 0.5. We choose a confidence level of 99%; that is, we will\n",
      "    reject the null hypothesis in favor of the alternative if the p-value is\n",
      "    less than 0.01.\n",
      "    \n",
      "    When testing random variates from the standard uniform distribution, which\n",
      "    has a mean of 0.5, we expect the data to be consistent with the null\n",
      "    hypothesis most of the time.\n",
      "    \n",
      "    >>> import numpy as np\n",
      "    >>> from scipy import stats\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> rvs = stats.uniform.rvs(size=50, random_state=rng)\n",
      "    >>> stats.ttest_1samp(rvs, popmean=0.5)\n",
      "    TtestResult(statistic=2.456308468440, pvalue=0.017628209047638, df=49)\n",
      "    \n",
      "    As expected, the p-value of 0.017 is not below our threshold of 0.01, so\n",
      "    we cannot reject the null hypothesis.\n",
      "    \n",
      "    When testing data from the standard *normal* distribution, which has a mean\n",
      "    of 0, we would expect the null hypothesis to be rejected.\n",
      "    \n",
      "    >>> rvs = stats.norm.rvs(size=50, random_state=rng)\n",
      "    >>> stats.ttest_1samp(rvs, popmean=0.5)\n",
      "    TtestResult(statistic=-7.433605518875, pvalue=1.416760157221e-09, df=49)\n",
      "    \n",
      "    Indeed, the p-value is lower than our threshold of 0.01, so we reject the\n",
      "    null hypothesis in favor of the default \"two-sided\" alternative: the mean\n",
      "    of the population is *not* equal to 0.5.\n",
      "    \n",
      "    However, suppose we were to test the null hypothesis against the\n",
      "    one-sided alternative that the mean of the population is *greater* than\n",
      "    0.5. Since the mean of the standard normal is less than 0.5, we would not\n",
      "    expect the null hypothesis to be rejected.\n",
      "    \n",
      "    >>> stats.ttest_1samp(rvs, popmean=0.5, alternative='greater')\n",
      "    TtestResult(statistic=-7.433605518875, pvalue=0.99999999929, df=49)\n",
      "    \n",
      "    Unsurprisingly, with a p-value greater than our threshold, we would not\n",
      "    reject the null hypothesis.\n",
      "    \n",
      "    Note that when working with a confidence level of 99%, a true null\n",
      "    hypothesis will be rejected approximately 1% of the time.\n",
      "    \n",
      "    >>> rvs = stats.uniform.rvs(size=(100, 50), random_state=rng)\n",
      "    >>> res = stats.ttest_1samp(rvs, popmean=0.5, axis=1)\n",
      "    >>> np.sum(res.pvalue < 0.01)\n",
      "    1\n",
      "    \n",
      "    Indeed, even though all 100 samples above were drawn from the standard\n",
      "    uniform distribution, which *does* have a population mean of 0.5, we would\n",
      "    mistakenly reject the null hypothesis for one of them.\n",
      "    \n",
      "    `ttest_1samp` can also compute a confidence interval around the population\n",
      "    mean.\n",
      "    \n",
      "    >>> rvs = stats.norm.rvs(size=50, random_state=rng)\n",
      "    >>> res = stats.ttest_1samp(rvs, popmean=0)\n",
      "    >>> ci = res.confidence_interval(confidence_level=0.95)\n",
      "    >>> ci\n",
      "    ConfidenceInterval(low=-0.3193887540880017, high=0.2898583388980972)\n",
      "    \n",
      "    The bounds of the 95% confidence interval are the\n",
      "    minimum and maximum values of the parameter `popmean` for which the\n",
      "    p-value of the test would be 0.05.\n",
      "    \n",
      "    >>> res = stats.ttest_1samp(rvs, popmean=ci.low)\n",
      "    >>> np.testing.assert_allclose(res.pvalue, 0.05)\n",
      "    >>> res = stats.ttest_1samp(rvs, popmean=ci.high)\n",
      "    >>> np.testing.assert_allclose(res.pvalue, 0.05)\n",
      "    \n",
      "    Under certain assumptions about the population from which a sample\n",
      "    is drawn, the confidence interval with confidence level 95% is expected\n",
      "    to contain the true population mean in 95% of sample replications.\n",
      "    \n",
      "    >>> rvs = stats.norm.rvs(size=(50, 1000), loc=1, random_state=rng)\n",
      "    >>> res = stats.ttest_1samp(rvs, popmean=0)\n",
      "    >>> ci = res.confidence_interval()\n",
      "    >>> contains_pop_mean = (ci.low < 1) & (ci.high > 1)\n",
      "    >>> contains_pop_mean.sum()\n",
      "    953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ttest_1samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also curious about salaries in the police force. The chief of police in Chicago claimed in a press briefing that salaries this year are higher than last year's mean of $86000/year a year for all salaried employees. Test this one sided hypothesis using a 95% confidence interval.\n",
    "\n",
    "Hint: A one tailed test has a p-value that is half of the two tailed p-value. If our hypothesis is greater than, then to reject, the test statistic must also be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "# Annual Salary\n",
    "\n",
    "'''\n",
    "mu = 86000        # media poblacional\n",
    "\n",
    "mu_hat = ??    # media muestral, media del experimento\n",
    "\n",
    "std_hat = ??    # std muestral, std del experimento\n",
    "\n",
    "n = 25161         # tamaño de la muestra\n",
    "''''''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101442,  94122, 101592, 110064,  50436, 103350,  93354,  84054,\n",
       "        87006, 102228,  84054,  91272, 111492,  95484,  65448,  90024,\n",
       "        82614,  48078,  76266,  48078])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_annual = np.array(salaries['Annual Salary'].dropna(), dtype=int)\n",
    "\n",
    "array_annual[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86786.99626405946"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_annual.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25161"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 86786.99626405946\n",
      "std 21040.933083200245\n"
     ]
    }
   ],
   "source": [
    "mean_annual = array_annual.mean()\n",
    "std_annual = array_annual.std()\n",
    "print('mean', mean_annual)\n",
    "print('std', std_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_annual = array_annual.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [101442  94122 101592 ...  90024  93354 115932]\n",
      "std [101442  94122 101592 ...  90024  93354 115932]\n"
     ]
    }
   ],
   "source": [
    "mean_annual = array_annual.mean()\n",
    "std_annual = array_annual.std()\n",
    "print('mean', array_annual)\n",
    "print('std', array_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_test = ttest_1samp(array_hourly, 30, alternative='two-sided')\n",
    "#t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence_interval = stats.t.interval(0.95, len(array_hourly)-1, loc=mean_hourly, scale=std_hourly)\n",
    "#confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `crosstab` function, find the department that has the most hourly workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department with the most hourly workers: STREETS & SAN\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "hourly_workers = salaries[salaries['Salary or Hourly'] == 'Hourly']\n",
    "\n",
    "hourly_counts = pd.crosstab(index=hourly_workers['Department'], columns='count')\n",
    "\n",
    "department_with_most_hourly_workers = hourly_counts.idxmax().get('count')\n",
    "\n",
    "print(\"Department with the most hourly workers:\", department_with_most_hourly_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workers from the department with the most hourly workers have complained that their hourly wage is less than $35/hour. Using a one sample t-test, test this one-sided hypothesis at the 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.6 , 21.43, 35.6 , 36.21, 35.6 , 36.13, 28.48, 36.21, 36.21,\n",
       "       36.21, 28.48, 20.77, 35.6 , 20.12, 35.6 , 36.21, 36.21, 36.21,\n",
       "       32.04, 36.21])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "dept_street = salaries[salaries['Department'] == 'STREETS & SAN']\n",
    "\n",
    "street_rate_array = dept_street['Hourly Rate'].dropna().values\n",
    "\n",
    "\n",
    "street_rate_array[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mu = 35        # media poblacional\n",
    "\n",
    "mu_hat = 33.72837808807734    # media muestral, media del experimento\n",
    "\n",
    "std_hat = 5.733701558944158    # std muestral, std del experimento\n",
    "\n",
    "n = 1862         # tamaño de la muestra\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(street_rate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 33.72837808807734\n",
      "std 5.733701558944158\n"
     ]
    }
   ],
   "source": [
    "mean_streat = street_rate_array.mean()\n",
    "std_street = street_rate_array.std()\n",
    "print('mean', mean_streat)\n",
    "print('std', std_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-9.567447887848152, pvalue=1.6689265282353859e-21, df=1861)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test = ttest_1samp(street_rate_array, 35, alternative='less')\n",
    "t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Constructing Confidence Intervals\n",
    "\n",
    "While testing our hypothesis is a great way to gather empirical evidence for accepting or rejecting the hypothesis, another way to gather evidence is by creating a confidence interval. A confidence interval gives us information about the true mean of the population. So for a 95% confidence interval, we are 95% sure that the mean of the population is within the confidence interval. \n",
    ").\n",
    "\n",
    "To read more about confidence intervals, click [here](https://en.wikipedia.org/wiki/Confidence_interval).\n",
    "\n",
    "\n",
    "In the cell below, we will construct a 95% confidence interval for the mean hourly wage of all hourly workers. \n",
    "\n",
    "The confidence interval is computed in SciPy using the `t.interval` function. You can read more about this function [here](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.t.html).\n",
    "\n",
    "To compute the confidence interval of the hourly wage, use the 0.95 for the confidence level, number of rows - 1 for degrees of freedom, the mean of the sample for the location parameter and the standard error for the scale. The standard error can be computed using [this](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sem.html) function in SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.046248541993936, 56.53086689056654)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "from scipy import stats\n",
    "confidence_interval = stats.t.interval(0.95, len(array_hourly)-1, loc=mean_hourly, scale=std_hourly)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now construct the 95% confidence interval for all salaried employeed in the police in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101442.,  94122.,  93354.,  84054.,  87006.,  84054.,  90024.,\n",
       "        48078.,  76266.,  48078.,  80016.,  72510.,  68616.,  90024.,\n",
       "        48078.,  76266.,  48078.,  72510.,  97440.,  72510.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_police = salaries[salaries['Department'] == 'POLICE']\n",
    "\n",
    "police_rate_array = dept_police['Annual Salary'].dropna().values\n",
    "\n",
    "\n",
    "police_rate_array[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 86486.41450313339\n",
      "std 18271.54668517837\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "mean_all = police_rate_array.mean()\n",
    "std_all = police_rate_array.std()\n",
    "print('mean', mean_all)\n",
    "print('std', std_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50671.60678895816, 122301.22221730862)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_interval = stats.t.interval(0.95, len(police_rate_array)-1, loc=mean_all, scale=std_all)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Hypothesis Tests of Proportions\n",
    "\n",
    "Another type of one sample test is a hypothesis test of proportions. In this test, we examine whether the proportion of a group in our sample is significantly different than a fraction. \n",
    "\n",
    "You can read more about one sample proportion tests [here](http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/SAS/SAS6-CategoricalData/SAS6-CategoricalData2.html).\n",
    "\n",
    "In the cell below, use the `proportions_ztest` function from `statsmodels` to perform a hypothesis test that will determine whether the number of hourly workers in the City of Chicago is significantly different from 25% at the 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "#Null hypothesis (H0): The proportion of hourly workers is equal to 25%.\n",
    "#Alternative hypothesis (H1): The proportion of hourly workers is different from 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8022\n",
      "33183\n"
     ]
    }
   ],
   "source": [
    "num_hourly_workers = np.sum(salaries['Salary or Hourly'] == 'Hourly')\n",
    "num_total_workers = len(salaries)\n",
    "print(num_hourly_workers)\n",
    "print(num_total_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05  # 95% confidence level\n",
    "expected_proportion = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of hourly workers is significantly different from 25%.\n"
     ]
    }
   ],
   "source": [
    "z_score, p_value = proportions_ztest(num_hourly_workers, num_total_workers, expected_proportion)\n",
    "if p_value < alpha:\n",
    "    print(\"The number of hourly workers is significantly different from 25%.\")\n",
    "else:\n",
    "    print(\"The number of hourly workers is not significantly different from 25%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
